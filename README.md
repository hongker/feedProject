## FeedProject
- 写扩撒，就是将一个内容写多份
- 读扩散，就是一个内容被多读
- 读写结合，部分读，部分写。
在不同的场景下可以采用不同的设计方式，读写扩散结合的模式实现的Feed流数据系统可以满足大部分应用场景。

## 核心原理
用户发布新内容，将Feed信息写入DB，同时写入Redis。通过异步的方式，有针对性的执行写扩散。
- 如普通用户的粉丝不多，直接写扩散也不会造成太多的存储空间浪费。
- 对于大V模式的用户，粉丝可能上百万，所以需要对粉丝进行分类，如分为活跃用户与僵尸用户，活跃用户往往占较小的比例，故对这部分粉丝采用写扩散同步Feed。
- 对于僵尸用户，在某个节点触发Feed流的初始化，可以根据不同的措施制定方案，如登录时执行异步初始化，或每间隔一定时间定时任务执行初始化。

## 功能模块设计
### User 用户
- 拉取最新Feed流数据
获取用户关注的目标用户发布的最新信息。

- 拉取历史Feed流数据
获取用户以前拉取过的历史Feed数据。

- 初始化Feed流
为不活跃用户刚登录时触发初始化，生成Feed流队列。

### Relation 关联
- 创建关注
用户选择目标用户，创建关注的关联。

- 取消关注
用户取消关注目标用户，更改关注状态为禁用。

### Feed 数据
- 发布最新的数据
用户发布新内容，写入DB，将Feed信息同步Redis.同时，针对一般用户，直接采用写扩散的模式，写入粉丝的feed队列。
对于大V类型的用户，因关注粉丝较多，直接采用写扩散会浪费存储空间，增加服务器的IO压力，是不合理的，所以对用户做区分，活跃用户占极少部分，直接采用写扩散模式。
对于僵尸粉，仅在登录时，触发Feed流初始化。

## 流程说明
![流程图](http://processon.com/chart_image/5e95759b7d9c0842ab38e5ff.png)

### 用户发布内容
- 1.写入DB
- 2.同步缓存

### 用户拉取最新数据
- 1.通过Offset分页获取用户关注的目标UID,Offset初始化为0
- 2.检查是否有获取到关注目标UID,更新Offset。如果没有，则跳出循环。
- 3.通过目标用户UID获取最新发布的Feed数据
- 4.检查数据的数量是否凑够请求所需要的量。如果不足，重复步骤1.
- 5.返回格式化后的响应内容。
- 6.将新Feed异步更新到历史Feed队列里。

### 用户获取历史数据

## 数据库设计
表模型:
![模型](http://processon.com/chart_image/5e966e09e401fd262e195b7f.png)

- 用户表
记录用户信息与状态

- 关系表
记录粉丝与用户的关联关系

- Feed表
记录用户的Feed信息内容

## 缓存设计
基于Redis设计缓存模块
- 基本定义
```
field: {creator_id}:{feed_id}
```
- Feed信息缓存
string类型,记录Feed的基本内容，如果用户更新Feed，只需更新这个key
```
key: user_field_info:{field}
value: {content:a,created_at:2020-04-15...}
```

- 用户的Feed流队列缓存
采用sorted set类型，
```
key: user_feed_queue:{user_id}
value: 
    - memeber : {field}
    - score: {feed_id}
```
注: 
- feed_id为基于时间生成的唯一ID,可用于按时间排序
- 刚开始采用的是list,但是对于历史数据的插入，sorted set比list更合适，因为它只需要`zadd`写入一条数据

## 其他
- 现在一般都是集群式的服务，分布式的请求场景下，应该考虑用分布式锁来保证一些环节的数据安全，虽然本Demo没有实现，但是实际环境下必须要考虑。
